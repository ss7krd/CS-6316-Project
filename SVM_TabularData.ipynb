{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3duwHfK4tK2E"
   },
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajm7yIzvtK2H"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "from csv import writer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h92oDj0otK2I"
   },
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP43DLAGtK2J"
   },
   "outputs": [],
   "source": [
    "def dataset_read(featurelist):\n",
    "    data = pd.read_csv('/content/drive/MyDrive/CS 6316 Project/hear_failure_tabular/heart_failure.csv')\n",
    "    data = data[featurelist]\n",
    "    #Normalization\n",
    "    data=np.array(data)\n",
    "    input_data_normed = data / data.max(axis=0)\n",
    "    #print(input_data_normed.shape)\n",
    "    return input_data_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmoW9cBBtK2J"
   },
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-c10RpTtK2K"
   },
   "outputs": [],
   "source": [
    "# 85/15 train/test split\n",
    "\n",
    "def dataset_split(input_data_normed):\n",
    "    training, test = input_data_normed[:int(.85*len(input_data_normed)),:], input_data_normed[int(.85*len(input_data_normed)):,:]\n",
    "    #label_training = training[:, 0]\n",
    "    #label_test = test[:, 0]\n",
    "    #test = np.delete(test, 0, 1)\n",
    "    return training,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDn0pn5BtK2K"
   },
   "outputs": [],
   "source": [
    "def training_1(training,test, splitting_ratio):\n",
    "    #np.seed\n",
    "    #np.random.shuffle(training)\n",
    "    train,valid = training[:int(splitting_ratio*len(training)),:], training[int(splitting_ratio*len(training)):,:]\n",
    "    label_train, label_valid = train[:, 0], valid[:, 0]\n",
    "    train = np.delete(train, 0, 1)\n",
    "    valid = np.delete(valid, 0, 1)\n",
    "    \n",
    "    #print(train.shape,label_train.shape)\n",
    "\n",
    "    #Run SVM\n",
    "    clf=SVC(kernel='rbf')\n",
    "    clf.fit(train, label_train)\n",
    "\n",
    "    label_test = test[:, 0]\n",
    "    test = np.delete(test, 0, 1)\n",
    "    \n",
    "    #print(test.shape,label_test.shape)\n",
    "    y_pred=clf.predict(test)\n",
    "    result = accuracy_score(label_test, y_pred)\n",
    "    return result\n",
    "    #print(\"Test Score: \", accuracy_score(label_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQD73EAytK2L"
   },
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vuqfs7ZNtK2M",
    "outputId": "bb928e9f-e734-44bb-e91e-a76b654a4617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Main Function, run for only one feature set\n",
    "\n",
    "cur_feature = ['Event', 'TIME', 'Gender', 'Smoking']\n",
    "\n",
    "input_data_normed = dataset_read(cur_feature)\n",
    "train,test = dataset_split(input_data_normed)\n",
    "\n",
    "training_1(train,test,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FMiv9qQtK2N"
   },
   "source": [
    "### FeatureSet selection (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_hmGPeitK2N"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/CS 6316 Project/hear_failure_tabular/heart_failure.csv')\n",
    "all_features = data.columns.tolist()\n",
    "all_features.remove('Event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_txPWHmttK2O",
    "outputId": "25a6979c-3f7d-4828-d64f-354c6cbf694d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def powerset(s):\n",
    "    x = len(s)\n",
    "    all_feature_set = []\n",
    "    for i in range(1 << x):\n",
    "        cur_list = [s[j] for j in range(x) if (i & (1 << j))]\n",
    "        #print(cur_list)\n",
    "        all_feature_set.append(cur_list)\n",
    "    return all_feature_set\n",
    "\n",
    "all_feature_set = powerset(all_features)\n",
    "len(all_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlKA6fortK2O"
   },
   "outputs": [],
   "source": [
    "def write_final_data(filename, List):\n",
    "\n",
    "    # Open our existing CSV file in append mode\n",
    "    # Create a file object for this file\n",
    "    with open(filename, 'a') as f_object:\n",
    "\n",
    "        # Pass this file object to csv.writer()\n",
    "        # and get a writer object\n",
    "        writer_object = writer(f_object)\n",
    "\n",
    "        # Pass the list as an argument into\n",
    "        # the writerow()\n",
    "        writer_object.writerow(List)\n",
    "\n",
    "        #Close the file object\n",
    "        f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKDGDjN-tK2P",
    "outputId": "ac861ffa-211a-4a7b-f37b-77fc35acf3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 3.92 s, total: 1min 52s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "splitting_ratio = .85\n",
    "\n",
    "for i in range(0, 3):\n",
    "    #filename = \"finalResult.csv\"\n",
    "    filename ='finalResultSVM_' + str(i+1) + '.csv'\n",
    "    \n",
    "    # opening the file with w+ mode truncates the file\n",
    "    f = open(filename, \"w+\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    for feature_set in all_feature_set:\n",
    "        cnt = cnt + 1\n",
    "        if(cnt==1):\n",
    "            continue\n",
    "        cur_feature_list = ['Event']+feature_set\n",
    "        #print(cur_feature_list)\n",
    "        input_data_normed = dataset_read(cur_feature_list)\n",
    "        train,test = dataset_split(input_data_normed)\n",
    "        result = training_1(train,test, splitting_ratio)\n",
    "        write_final_data(filename, [cur_feature_list, result])\n",
    "    \n",
    "    splitting_ratio = splitting_ratio + .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58Q11eCJtK2P"
   },
   "source": [
    "### Read from CSV file to find the **maximum accuracy** and **best feautre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZkCs1SVtK2P"
   },
   "outputs": [],
   "source": [
    "def best_feature(data, maxAcc):\n",
    "    \n",
    "    best_feature = []\n",
    "    len_best_feature = 100000\n",
    "\n",
    "    for i in range(0, len(data), 1):\n",
    "        if data[i][1] == maxAcc:\n",
    "            best_feature.append(data[i][0])\n",
    "            if len(data[i][0]) < len_best_feature:\n",
    "                len_best_feature = len(data[i][0])\n",
    "                feature = data[i][0]\n",
    "    \n",
    "    print_function(feature, maxAcc, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqNLMVlZtK2Q"
   },
   "outputs": [],
   "source": [
    "def print_function(feature, maxAcc, best_feature):\n",
    "\n",
    "    print(\"Best Feature List\", feature)\n",
    "    print(\"Maximum Accuracy: \", maxAcc)\n",
    "    print()\n",
    "    #print(\"All Feature List: \\n\", best_feature)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vd8nR2CjtK2Q"
   },
   "outputs": [],
   "source": [
    "def best_feature_func():\n",
    "    for i in range(0, 3):\n",
    "        #filename = \"finalResult.csv\"\n",
    "        filename ='finalResultSVM_' + str(i+1) + '.csv'\n",
    "        with open(filename, newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = list(reader)\n",
    "\n",
    "        data = np.array(data)\n",
    "        data.shape\n",
    "\n",
    "        accList = []\n",
    "        for i in range(0, len(data), 1):\n",
    "            accList.append(data[i][1])\n",
    "\n",
    "        maxAcc = max(accList)\n",
    "        best_feature(data, maxAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9kEabXhtK2Q",
    "outputId": "1c8768ba-4fe2-4ab9-df2a-c8bce4b766ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature List ['Event', 'TIME', 'Ejection.Fraction', 'Creatinine']\n",
      "Maximum Accuracy:  0.9555555555555556\n",
      "\n",
      "\n",
      "\n",
      "Best Feature List ['Event', 'TIME', 'Age', 'Ejection.Fraction']\n",
      "Maximum Accuracy:  0.9555555555555556\n",
      "\n",
      "\n",
      "\n",
      "Best Feature List ['Event', 'TIME', 'Ejection.Fraction', 'Sodium']\n",
      "Maximum Accuracy:  0.9555555555555556\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_feature_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDCD91RctK2R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/heart_failure.csv')\n",
    "# S = np.loadtxt('/content/drive/My Drive/Colab Notebooks/data.txt')\n",
    "\n",
    "#Normalization\n",
    "data=np.array(data)\n",
    "input_data_normed = data / data.max(axis=0)\n",
    "\n",
    "training, test = input_data_normed[:int(.85*len(input_data_normed)),:], input_data_normed[int(.85*len(input_data_normed)):,:]\n",
    "label_training = training[:, 1]\n",
    "label_test = test[:, 1]\n",
    "test = np.delete(test, 1, 1)\n",
    "\n",
    "np.random.shuffle(training)\n",
    "train,valid = training[:int(.95*len(input_data_normed)),:], input_data_normed[int(.95*len(input_data_normed)):,:]\n",
    "label_train, label_valid = train[:, 1], valid[:, 1]\n",
    "train = np.delete(train, 1, 1)\n",
    "valid = np.delete(valid, 1, 1)\n",
    "\n",
    "#Run SVM\n",
    "clf=SVC(kernel='rbf', C = 2.0)\n",
    "clf.fit(train, label_train)\n",
    "y_pred=clf.predict(valid)\n",
    "\n",
    "print(\"Validation Score: \", accuracy_score(label_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for combinations of hyper-parameters\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "\n",
    "\n",
    "# Clist = [0.02, 0.05, 0.08, 1.1, 1.3, 1.5.0]\n",
    "# gamma_list = [0.01, 1.0, 10]\n",
    "\n",
    "\n",
    "expected_loss_list = []\n",
    "bias_list = []\n",
    "variance_list = []\n",
    "clist_forGraph = []\n",
    "gammaList_forGraph = []\n",
    "\n",
    "minExpectedLoss = 1000000000000000\n",
    "best_cValue = -1\n",
    "best_gammaValue = -1\n",
    "# itr = 1\n",
    "for cValue in np.arange(0.1, 2.1, 0.1):\n",
    "  for gammaValue in np.arange(0.01, 1, 0.03):\n",
    "    # print(itr)\n",
    "    # itr = itr + 1\n",
    "    clf=SVC(kernel='rbf', C = cValue, gamma = gammaValue)\n",
    "    expected_loss, bias, variance = bias_variance_decomp(\n",
    "        clf, train, label_train, valid, label_valid, \n",
    "        loss='0-1_loss', num_rounds = 400,\n",
    "        random_seed=123)\n",
    "    if expected_loss < minExpectedLoss:\n",
    "      minExpectedLoss = expected_loss\n",
    "      best_cValue = cValue\n",
    "      best_gammaValue = gammaValue\n",
    "    \n",
    "    expected_loss_list.append(expected_loss)\n",
    "    bias_list.append(bias)\n",
    "    variance_list.append(variance)\n",
    "\n",
    "    clist_forGraph.append(cValue)\n",
    "    gammaList_forGraph.append(gammaValue)\n",
    "\n",
    "    # print(expected_loss, bias, variance)\n",
    "\n",
    "print(\"Best hyperparameters:\", best_cValue, best_gammaValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for graph\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "\n",
    "\n",
    "# Clist = [0.02, 0.05, 0.08, 1.1, 1.3, 1.5.0]\n",
    "# gamma_list = [0.01, 1.0, 10]\n",
    "\n",
    "\n",
    "expected_loss_list = []\n",
    "bias_list = []\n",
    "variance_list = []\n",
    "clist_forGraph = []\n",
    "gammaList_forGraph = []\n",
    "\n",
    "# itr = 1\n",
    "# for cValue in np.arange(0.1, 2.1, 0.1):\n",
    "minExpectedLoss = 10000000000\n",
    "best_gammaValue = -1\n",
    "for gammaValue in np.arange(0.3, 1.0, 0.01):\n",
    "    # print(itr)\n",
    "    # itr = itr + 1\n",
    "    clf=SVC(kernel='rbf', C = 1.0, gamma = gammaValue)\n",
    "    expected_loss, bias, variance = bias_variance_decomp(\n",
    "        clf, train, label_train, valid, label_valid, \n",
    "        loss='0-1_loss', num_rounds = 400,\n",
    "        random_seed=123)\n",
    "    if expected_loss < minExpectedLoss:\n",
    "      minExpectedLoss = expected_loss\n",
    "      best_gammaValue = gammaValue\n",
    "    \n",
    "    expected_loss_list.append(expected_loss)\n",
    "    bias_list.append(bias*bias)\n",
    "    variance_list.append(variance)\n",
    "\n",
    "    # clist_forGraph.append(cValue)\n",
    "    gammaList_forGraph.append(gammaValue)\n",
    "    \n",
    "#draw graph\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig = plt.figure()\n",
    " \n",
    "# ax = plt.axes(projection ='3d')\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle('C=1.0')\n",
    "ax.plot(gammaList_forGraph, expected_loss_list, 'red', label='Expected loss')\n",
    "ax.plot(gammaList_forGraph, bias_list, 'green', label = 'Bias'r'$^2$')\n",
    "ax.plot(gammaList_forGraph, variance_list, 'blue', label = 'Variance')\n",
    "# ax.plot3D(clist_forGraph, gammaList_forGraph, expected_loss_list, 'green')\n",
    "# ax.plot3D(clist_forGraph, gammaList_forGraph, bias_list, 'red')\n",
    "# ax.plot3D(clist_forGraph, gammaList_forGraph, variance_list, 'blue')\n",
    "ax.set_xlabel('gamma', fontsize = 14)\n",
    "ax.set_ylabel('Loss value', fontsize = 14)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SVM_TabularData_tonmoy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
