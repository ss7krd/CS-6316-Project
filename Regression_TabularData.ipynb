{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHUNZYCArtRu"
   },
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNSim6tWrtRy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "from csv import writer\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bOEjDEarwE6",
    "outputId": "48f321c5-adbd-4532-a276-205a2d212c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycdPUyV7rtRz"
   },
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBVWd2hFrtR0"
   },
   "outputs": [],
   "source": [
    "def dataset_read(featurelist):\n",
    "    data = pd.read_csv('/content/drive/MyDrive/CS 6316 Project/hear_failure_tabular/heart_failure.csv')\n",
    "    data = data[featurelist]\n",
    "    #Normalization\n",
    "    data=np.array(data)\n",
    "    input_data_normed = data / data.max(axis=0)\n",
    "    #print(input_data_normed.shape)\n",
    "    return input_data_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rSdr-RtrtR0"
   },
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7juC8Z9rtR1"
   },
   "outputs": [],
   "source": [
    "# 85/15 train/test split\n",
    "\n",
    "def dataset_split(input_data_normed):\n",
    "    training, test = input_data_normed[:int(.85*len(input_data_normed)),:], input_data_normed[int(.85*len(input_data_normed)):,:]\n",
    "    #label_training = training[:, 0]\n",
    "    #label_test = test[:, 0]\n",
    "    #test = np.delete(test, 0, 1)\n",
    "    return training,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WlTAe8TrtR1"
   },
   "outputs": [],
   "source": [
    "def training_1(training,test, splitting_ratio):\n",
    "    #np.seed\n",
    "    #np.random.shuffle(training)\n",
    "    train,valid = training[:int(splitting_ratio*len(training)),:], training[int(splitting_ratio*len(training)):,:]\n",
    "    label_train, label_valid = train[:, 0], valid[:, 0]\n",
    "    train = np.delete(train, 0, 1)\n",
    "    valid = np.delete(valid, 0, 1)\n",
    "    \n",
    "    #print(train.shape,label_train.shape)\n",
    "\n",
    "    #Run Logistic Regression\n",
    "    #clf=SVC(kernel='rbf')\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(train, label_train)\n",
    "\n",
    "    label_test = test[:, 0]\n",
    "    test = np.delete(test, 0, 1)\n",
    "    \n",
    "    #print(test.shape,label_test.shape)\n",
    "    y_pred=clf.predict(test)\n",
    "    result = accuracy_score(label_test, y_pred)\n",
    "    return result\n",
    "    #print(\"Test Score: \", accuracy_score(label_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1qctmeFrtR2"
   },
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scPI7LcmrtR3",
    "outputId": "70e6077f-ddad-49cc-9dd2-eddcf6a1a720"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444444444444444"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Main Function, run for only one feature set\n",
    "\n",
    "cur_feature = ['Event', 'TIME', 'Gender', 'Smoking']\n",
    "\n",
    "input_data_normed = dataset_read(cur_feature)\n",
    "train,test = dataset_split(input_data_normed)\n",
    "\n",
    "training_1(train,test,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCou-E_hrtR4"
   },
   "source": [
    "### FeatureSet selection (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hzlRfSYrtR4"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/CS 6316 Project/hear_failure_tabular/heart_failure.csv')\n",
    "all_features = data.columns.tolist()\n",
    "all_features.remove('Event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXIScx5CrtR5",
    "outputId": "b25f3280-9343-4aa2-ea44-10854450a558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def powerset(s):\n",
    "    x = len(s)\n",
    "    all_feature_set = []\n",
    "    for i in range(1 << x):\n",
    "        cur_list = [s[j] for j in range(x) if (i & (1 << j))]\n",
    "        #print(cur_list)\n",
    "        all_feature_set.append(cur_list)\n",
    "    return all_feature_set\n",
    "\n",
    "all_feature_set = powerset(all_features)\n",
    "len(all_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KOrnYQ-rtR5"
   },
   "outputs": [],
   "source": [
    "def write_final_data(filename, List):\n",
    "\n",
    "    # Open our existing CSV file in append mode\n",
    "    # Create a file object for this file\n",
    "    with open(filename, 'a') as f_object:\n",
    "\n",
    "        # Pass this file object to csv.writer()\n",
    "        # and get a writer object\n",
    "        writer_object = writer(f_object)\n",
    "\n",
    "        # Pass the list as an argument into\n",
    "        # the writerow()\n",
    "        writer_object.writerow(List)\n",
    "\n",
    "        #Close the file object\n",
    "        f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtzyNwp5rtR6",
    "outputId": "ed5785c5-b142-40c8-e2ce-81443f72f4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 3.57 s, total: 2min\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "splitting_ratio = .85\n",
    "\n",
    "for i in range(0, 3):\n",
    "    #filename = \"finalResult.csv\"\n",
    "    filename ='finalResultRegression_' + str(i+1) + '.csv'\n",
    "    \n",
    "    # opening the file with w+ mode truncates the file\n",
    "    f = open(filename, \"w+\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    for feature_set in all_feature_set:\n",
    "        cnt = cnt + 1\n",
    "        if(cnt==1):\n",
    "            continue\n",
    "        cur_feature_list = ['Event']+feature_set\n",
    "        #print(cur_feature_list)\n",
    "        input_data_normed = dataset_read(cur_feature_list)\n",
    "        train,test = dataset_split(input_data_normed)\n",
    "        result = training_1(train,test, splitting_ratio)\n",
    "        write_final_data(filename, [cur_feature_list, result])\n",
    "    \n",
    "    splitting_ratio = splitting_ratio + .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJSxIm4nrtR6"
   },
   "source": [
    "### Read from CSV file to find the **maximum accuracy** and **best feautre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obzJAlMHrtR6"
   },
   "outputs": [],
   "source": [
    "def best_feature(data, maxAcc):\n",
    "    \n",
    "    best_feature = []\n",
    "    len_best_feature = 100000\n",
    "\n",
    "    for i in range(0, len(data), 1):\n",
    "        if data[i][1] == maxAcc:\n",
    "            best_feature.append(data[i][0])\n",
    "            if len(data[i][0]) < len_best_feature:\n",
    "                len_best_feature = len(data[i][0])\n",
    "                feature = data[i][0]\n",
    "    \n",
    "    print_function(feature, maxAcc, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8zk9TkkrtR7"
   },
   "outputs": [],
   "source": [
    "def print_function(feature, maxAcc, best_feature):\n",
    "\n",
    "    print(\"Best Feature List\", feature)\n",
    "    print(\"Maximum Accuracy: \", maxAcc)\n",
    "    print()\n",
    "    #print(\"All Feature List: \\n\", best_feature)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpKFjnmdrtR7"
   },
   "outputs": [],
   "source": [
    "def best_feature_func():\n",
    "    for i in range(0, 3):\n",
    "        #filename = \"finalResult.csv\"\n",
    "        filename ='finalResultRegression_' + str(i+1) + '.csv'\n",
    "        with open(filename, newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = list(reader)\n",
    "\n",
    "        data = np.array(data)\n",
    "        data.shape\n",
    "\n",
    "        accList = []\n",
    "        for i in range(0, len(data), 1):\n",
    "            accList.append(data[i][1])\n",
    "\n",
    "        maxAcc = max(accList)\n",
    "        best_feature(data, maxAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdObTC4brtR7",
    "outputId": "2d7a4c80-b381-4608-feae-69defec40dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature List ['Event', 'TIME', 'Smoking', 'Ejection.Fraction']\n",
      "Maximum Accuracy:  0.9555555555555556\n",
      "\n",
      "\n",
      "\n",
      "Best Feature List ['Event', 'TIME', 'Gender', 'Ejection.Fraction', 'Sodium']\n",
      "Maximum Accuracy:  0.9555555555555556\n",
      "\n",
      "\n",
      "\n",
      "Best Feature List ['Event', 'TIME', 'Smoking', 'BP', 'Ejection.Fraction']\n",
      "Maximum Accuracy:  0.9555555555555556\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_feature_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZHiT1CMrtR7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/heart_failure.csv')\n",
    "\n",
    "#Normalization\n",
    "data=np.array(data)\n",
    "input_data_normed = data / data.max(axis=0)\n",
    "\n",
    "training, test = input_data_normed[:int(.85*len(input_data_normed)),:], input_data_normed[int(.85*len(input_data_normed)):,:]\n",
    "label_training = training[:, 1]\n",
    "label_test = test[:, 1]\n",
    "test = np.delete(test, 1, 1)\n",
    "\n",
    "np.random.shuffle(training)\n",
    "train,valid = training[:int(.95*len(input_data_normed)),:], input_data_normed[int(.95*len(input_data_normed)):,:]\n",
    "label_train, label_valid = train[:, 1], valid[:, 1]\n",
    "train = np.delete(train, 1, 1)\n",
    "valid = np.delete(valid, 1, 1)\n",
    "print(train.shape, valid.shape)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(train, label_train)\n",
    "print(\"Validation Score: \", clf.score(valid, label_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for best hyper-parameter\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "# Clist = [0.02, 0.05, 0.08, 1.1, 1.3, 1.5.0]\n",
    "# gamma_list = [0.01, 1.0, 10]\n",
    "expected_loss_list = []\n",
    "bias_list = []\n",
    "variance_list = []\n",
    "clist_forGraph = []\n",
    "# gammaList_forGraph = []\n",
    "\n",
    "# itr = 1\n",
    "# for cValue in np.arange(0.1, 2.1, 0.1):\n",
    "minExpectedLoss = 10000000000\n",
    "best_cValue = -1\n",
    "for cValue in np.arange(6, 12, 0.1):\n",
    "    # print(itr)\n",
    "    # itr = itr + 1\n",
    "    clf=LogisticRegression(random_state=0, C = cValue)\n",
    "    expected_loss, bias, variance = bias_variance_decomp(\n",
    "        clf, train, label_train, valid, label_valid, \n",
    "        loss='0-1_loss', num_rounds = 800,\n",
    "        random_seed=123)\n",
    "    if expected_loss < minExpectedLoss:\n",
    "      minExpectedLoss = expected_loss\n",
    "      best_cValue = cValue\n",
    "    \n",
    "    expected_loss_list.append(expected_loss)\n",
    "    bias_list.append(bias*bias)\n",
    "    variance_list.append(variance)\n",
    "\n",
    "    clist_forGraph.append(cValue)\n",
    "    # gammaList_forGraph.append(gammaValue)\n",
    "\n",
    "print(\"Best C Value:\", best_cValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw graph\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig = plt.figure()\n",
    " \n",
    "# ax = plt.axes(projection ='3d')\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "# fig.suptitle('gamma=0.39')\n",
    "ax.plot(clist_forGraph, expected_loss_list, 'red', label='Expected loss')\n",
    "ax.plot(clist_forGraph, bias_list, 'green', label = 'Bias'r'$^2$')\n",
    "ax.plot(clist_forGraph, variance_list, 'blue', label = 'Variance')\n",
    "# ax.plot3D(clist_forGraph, gammaList_forGraph, expected_loss_list, 'green')\n",
    "# ax.plot3D(clist_forGraph, gammaList_forGraph, bias_list, 'red')\n",
    "# ax.plot3D(clist_forGraph, gammaList_forGraph, variance_list, 'blue')\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Loss value')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Regression_TabularData_Tonmoy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
