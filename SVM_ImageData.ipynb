{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jW4lFUeNQXiL"
   },
   "source": [
    "##Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUu6cLPstb-S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam_v2, adagrad_v2, adadelta_v2, sgd_experimental, rmsprop_v2\n",
    "# from keras.optimizers import Adam, Adagrad, Adadelta, SGD, RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D\n",
    "from keras.layers import Flatten, MaxPool2D, MaxPooling2D, BatchNormalization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FBnPG7UQi4X"
   },
   "source": [
    "##Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuxKa-HTH4S-"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/MyDrive/Dataset_BUSI_with_GT/\"\n",
    "imagepatches = glob(\"/content/drive/MyDrive/Dataset_BUSI_with_GT/**/*).png\",recursive=True)\n",
    "# for filename in imagepatches[0:10]:\n",
    "#   print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHfVJDRiI1N3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class0 = []\n",
    "class1 = []\n",
    "class2 = []\n",
    "\n",
    "for filename in imagepatches:\n",
    "  if filename.find(\"normal\") != -1:\n",
    "    class0.append(filename)\n",
    "  elif filename.find(\"malignant\") != -1:\n",
    "    class1.append(filename)\n",
    "  else:\n",
    "    class2.append(filename)\n",
    "\n",
    "#randomizing the values\n",
    "sample_class0 = random.sample(class0,len(class0))\n",
    "sample_class1 = random.sample(class1,len(class1))\n",
    "sample_class2 = random.sample(class2,len(class2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SrFEl_CeXdU"
   },
   "outputs": [],
   "source": [
    "#for image resoltuion 50\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "\n",
    "size = 128\n",
    "def get_image_arrays(data,label,size=(50,50)):\n",
    "  img_arrays = []\n",
    "  for i in data:\n",
    "    if i.endswith(\".png\"):\n",
    "      img = cv2.imread(i,cv2.IMREAD_COLOR)\n",
    "      img_sized = cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)\n",
    "      img_arrays.append([img_sized.flatten(),label])\n",
    "  return img_arrays\n",
    "\n",
    "# class0_array_50 = get_image_arrays(sample_class0,0,(size,size))\n",
    "# class1_array_50 = get_image_arrays(sample_class1,1,(size,size))\n",
    "# class2_array_50 = get_image_arrays(sample_class2,2,(size,size))\n",
    "\n",
    "class0_array_128 = get_image_arrays(sample_class0,0,(size,size))\n",
    "class1_array_128 = get_image_arrays(sample_class1,1,(size,size))\n",
    "class2_array_128 = get_image_arrays(sample_class2,2,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owcur9dDSX1x",
    "outputId": "6eb25785-bf13-4948-b7f5-c19ec4af3ef1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# combined_data = np.concatenate((class0_array_50,class1_array_50))\n",
    "# combined_data = np.concatenate((combined_data,class2_array_50))\n",
    "\n",
    "combined_data = np.concatenate((class0_array_128,class1_array_128))\n",
    "combined_data = np.concatenate((combined_data,class2_array_128))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dR1g8ExdT7rn",
    "outputId": "3f9854f6-facd-41c1-80c4-82d5a4267749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780, 49152)\n"
     ]
    }
   ],
   "source": [
    "def combined_data_fn(combined_data, shape = (-1,128,128,3)):\n",
    "  X = []\n",
    "  y = []\n",
    "  for features,label in combined_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "  flat_data=np.array(X)\n",
    "  target=np.array(y)\n",
    "  df=pd.DataFrame(flat_data) #dataframe\n",
    "  df['Target']=target\n",
    "  x=df.iloc[:,:-1] #input data \n",
    "  y=df.iloc[:,-1] #output data\n",
    "  print(x.shape)\n",
    "  return x,y\n",
    "\n",
    "x, y = combined_data_fn(combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6VIjkE7SJQ3"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD3gehlbtL1y"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def make_model(C = 1,gamma = 'scale',kernel = 'rbf'):\n",
    "  param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
    "  svc=svm.SVC(probability=True)\n",
    "  model=GridSearchCV(svc,param_grid)\n",
    "  clf= svm.SVC(C = C, gamma = gamma, kernel='rbf')\n",
    "  return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgCcoOXgtP1J",
    "outputId": "b5280710-8777-4a82-c889-e828cf34e95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Splitted\n",
      "Training Model\n",
      "The Model is trained well with the given images\n",
      "The model is 82.05128205128204% accurate\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "##Dataset Split into train, test, validation set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.10,random_state=77,stratify=y)\n",
    "# x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.05,random_state=77,stratify=y_train)\n",
    "print('Dataset Splitted')\n",
    "\n",
    "\n",
    "\n",
    "clf = make_model(C = 10,gamma = 0.5,kernel = 'rbf')\n",
    "print(\"Training Model\")\n",
    "clf.fit(x_train,y_train)\n",
    "print('The Model is trained well with the given images')\n",
    "# model.best_params_ contains the best parameters obtained from GridSearchCV\n",
    "\n",
    "y_pred=clf.predict(x_test)\n",
    "print(f\"The model is {accuracy_score(y_pred,y_test)*100}% accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlEmKTWOwjiu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SVM_imageData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
